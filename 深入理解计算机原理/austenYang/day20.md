**虚拟内存**：计算机系统内存管理的一种技术。它使得应用程序认为它拥有连续可用的内存（一个连续完整的地址空间）。而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。

> 思考：对于应用程序来说，虚拟内存，对应到硬件上，这个硬件可以是 物理内存，可以是 外部磁盘存储器。因为对于程序而言，它只需要一个连续可用的内存。虚拟内存是最终映射到硬件上，不管是磁盘还是内存，对于程序而言它只是一种结果。不一定非要正真的内存硬件。
>
> 把内存扩展到磁盘只是使用虚拟内存技术的一个结果，它的作用也可以通过[覆盖](https://zh.wikipedia.org/wiki/覆盖_(编程))或者把处于不活动状态的程序以及它们的数据全部交换到磁盘上等方式来实现。

CPU 芯片上有叫做 **内存管理单元** 的专门硬件，利用放在主存中的查询表来动态翻译虚拟地址，该表的内容由操作系统管理。

在任意时刻，虚拟页面的集合都分为三个不相交的子集：

* 未分配
* 缓存的
* 未缓存的



### 9.3.1 DRAM 缓存的组织结构

术语 SRAM 缓存表示位于 CPU 和 主存之间的 L1、L2 和 L3 高速缓存，并且用术语 DRAM 缓存表示 虚拟内存系统的缓存，它在主存中缓存虚拟页。

### 9.3.2 页表

页表就是一个页表条目（Page Table Entry,PTE）的数组。

### 9.3.3 页命中

### 9.3.3 缺页

从缺页到载次命中。

在虚拟内存中，块称为 页。磁盘和内存之间传送页的活动叫做 **交换（swapping）** 或者 **页面调度（paging）**。页从磁盘 **换入** DRMA 和从 DRAM **换出** 磁盘。当有不命中发生时，才换入页面的这种策略称为 **按需页面调度（damand paging）**。

### 9.3.5 分配页面

当操作系统分配一个新的虚拟内存页时，

### 9.3.6

只有我们的程序有好的时间局部性，虚拟内存就能工作的相当好。如果工作集的大小超出了物理内存的大小，那么程序将产生一种不不幸的状态，叫做 **抖动（thrashing）**,这时页面将不断的 换进换出。虽然虚拟内存通常是有效的，但是如果程序性能慢得想爬一样，那么就可能发生了抖动。

### 9.4 虚拟内存作为内存管理的工具

实际上，操作系统为每个进程提供了一个独立的页表，因而也就是一个独立的虚拟地址空间。

![image-20200620204457913](https://note-austen-1256667106.cos.ap-beijing.myqcloud.com/2020-06-20-124500.png)

注意，多个虚拟页面可以映射到同一个共享物理页面上。

**按需页面调度** 和 **独立的虚拟地址空间** 结合，对系统中内存的使用和管理造成了深远的影响。特别地，VM 简化了链接和加载、代码和数据共享，以及应用程序的内存分配。

* 简化链接

独立的地址空间允许每个进程的内存映射像使用相同的基本格式，而不管代码和数据实际存放在物理内存何处。

* 简化加载

虚拟内存使得容易向内存中加载 可执行文件 和 共享对象文件。要把目标文件中 .text 和 .data 加载到一个新创建的进程中，Linxu 加载器为代码和数据段分配虚拟页，把它们标记为无效的（即未被缓存的），将页表条目指向目标文件中适当的位置。有趣的是，加载器从来不会从磁盘到内存复制任何数据。每个页初次被引用时，要么是 CPU 取指令引用的，要么是执行一条正在执行的指令引用一个内存位置时引用的，虚拟内存会按照需要自动地调入数据页。



* 简化共享

独立地址空间为操作系统提供了一个管理用户进程和操作系统自身之间共享的一种机制。一般而言每个进程都有自己私有的代码、数据、堆及栈区域，是不和其他进程共享的。



然而，在一些情况下还需要进程来共享代码和数据。例如，每个进程必须调用相同的操作系统内核代码，而每个 C 程序都会调用 C 标准库中的程序，比如 printf。**操作系统通过将不同进程中适当的虚拟页面映射到相同的物理页面，从而安排多个进程共享这部分代码的副本，而不是在每个进程中都包括单独的内核和 C 标准库的副本**

* 简化内存分配

虚拟内存为用户进程提供一个简单的分配额外内存的机制。当一个运行在用户进程的程序要求额外的堆空间时（如调用 `malloc`的结果），操作系统分配一个适当数字（例如 k）个连续的虚拟内存页面，并映射到物理内存中任意位置的 k 个任务的物理页面。由于页表工作的方式，操作系统没有必要分配 k 个连续的物理内存页面。页面可以随机的分散在物理内存中。

### 9.5 虚拟内存包含内存



![image-20200620213433148](https://note-austen-1256667106.cos.ap-beijing.myqcloud.com/2020-06-20-133439.png)

SUP 位表示进程是否必须运行在内核（超级用户）模式下才能访问该页面。运行在内核模式下可以访问任何页面，但是允许在用户模式中进程只允许访问那些 SUP 为 0 的页面。READ 位和 WRITE 位控制对页面的读写访问。

### 9.3 地址翻译

地址翻译是一个 N 元素的虚拟地址空间中的元素和一个 M 元素的物理地址空间中元素之间的映射。

![image-20200620215551111](https://note-austen-1256667106.cos.ap-beijing.myqcloud.com/2020-06-20-135552.png)

上图展示了 MMU 如何利用页表来实现映射。CPU 中的一个控制寄存器，**页表基址寄存器（Page Table Base Register,PTBR）** 指向当前页表。n 位虚拟地址包含两个部分：一个 p 位的虚拟页面偏移（Virtual Page Offset, VPO）和一个（n - p）位的虚拟页好（Virtual Page Numner,VPN）。

MMU 利用 VPN 来选择适当的 PTE 。例如，VPN 0 选择 PTE 0，VPN 1 选择 PTE 1,以此类推。将页表条目中 物理页号（Physical Page Number,PPN）和虚拟地址中的 VPO 串联起来，就是相应的物理地址。

### 9.6.1 结合高速缓存和虚拟内存

在任何即使用 虚拟内存 又使用 SRAM 高速缓存的系统中，都有应该使用虚拟地址还是使用物理地址来访问 SRAM高速缓存的问题。

大多数系统中是选择使用物理寻址的。使用物理寻址，多个进程同时在高速缓存中有存储块和共享来自相同的虚拟页面的块 称为很简单的事前。

### 9.6.2 利用 TLB 加速地址翻译

每次 CPU 产生一个虚拟地址，MMU 就必须查阅一个 PET，以便将虚拟地址翻译为物理地址。

翻译后备缓冲器（Translation Lookaside Buffer,TLB）。TLB是一个小的，虚拟寻址的缓存，其中每一行都保存着一个由单个 PTE 组成的块。TLB 通常有高度的相关联度。

![image-20200620233859883](https://note-austen-1256667106.cos.ap-beijing.myqcloud.com/2020-06-20-153901.png)

![image-20200620234150223](https://note-austen-1256667106.cos.ap-beijing.myqcloud.com/2020-06-20-154152.png)