### 第五章 优化程序性能

* 编写高效的程序需要以下几点
  * 选择一组适当的算法和数据结构
  * 写出编译器能够有效优化以转换成高效可执行代码的源代码
* 为了使程序性能最大化，程序要和编译器都需要一个目标机器的模型，指明如何处理指令，以及各个操作的时序性
* 利用程序的指令级并行能力，同时执行多条指令

#### 优化编译器的能力和局限性

* 现代编译器运用复杂精细的算法来确定一个程序中计算的是什么值，以及它们是被如何使用的，然后会利用一些机会来简化表达式，在几个不同的地方使用同一个计算，以及降低一个给定的计算必须被执行的次数
  * 比如 GCC 编译器以命令选项 “-Og” 调用 GCC 是让 GCC使用一组基本的优化，-O1或更高（-O2 或 -O3）调用 GCC 会让它使用更大量的优化
  * 两个指针可能指向同一个内存位置的情况称为 内存别名使用，在只执行安全的优化中，编译器必须假设不同的指针可能会指向内存中同一个位置
  * **内存别名的使用可能会导致意想不到的程序行为，从而限制优化策略**

```c++
// 6 次内存引用（2次读 *xp，2次读 *yp，2次写 *xp）
void twiddle1(long *xp,long *yp){
    *xp += *yp;
    *xp += *yp;
}

// 3 次内存引用（读 *xp，读 *yp，写 *xp）
void twiddle2(long *xp,long *yp){
    *xp += 2 * *yp;
}

// 上面的代码要考虑到 xp = yp 的情况，如果 xp = yp twiddle1 为 xp 的 4 倍，而 twiddle2 为 xp 的 3 倍
```

#### 表示程序的性能

* 我们引入度量标准**每元素的周期数（CPE）**，作为一种表示程序性能并指导我们改进代码的方法。CPE 这种度量标准帮助我们在更细节上理解迭代程序的循环性能，CPE 越小，证明程序的性能越好

#### 程序示例

* 下面的例子说明一个抽象的程序是如何被系统的转换成有效代码

```c++
typedef long data_t;

typedef struct {
    long len;
    data_t *data;
} vec_rec, *vec_ptr;

// 创建 vec 
vec_ptr new_vec(long len) {
    vec_ptr result = (vec_ptr) malloc(sizeof(vec_rec));
    data_t *data = NULL;
    if (!result) {
        return NULL;
    }
    result->len = len;
    if (len > 0) {
        data = (data_t *) calloc(len, sizeof(data_t));
        if (!data) {
            free(result);
            return NULL;
        }
    }
    result->data = data;
    return result;
}

// 获取指定位置的一条数据
int get_vec_element(vec_ptr v, long index, data_t *dest) {
    if (index < 0 || index >= v->len) {
        return 0;
    }
    *dest = v->data[index];
    return 1;
}

// 返回 vec 长度
long vec_length(vec_ptr v) {
    return v->len;
}

#define IDENT 0
#define OP +

// 获取 data_t 的总和
void combine1(vec_ptr v, data_t *dest) {
    long i;
    *dest = IDENT;
    for (int i = 0; i < vec_length(v); ++i) {
        data_t val;
        get_vec_element(v, i, &val);
        *dest = *dest OP val;
    }
}
```

##### 消除循环的低效率

* combine1 调用函数 vec_length(v) 作为 for 循环的测试条件，循环翻译成机器级程序，每次循环迭代时都必须对测试条件求值，并且向量的长度不会随着循环的进行而改变，因此只要计算一次向量的长度就可以了

优化后的代码

```c++
void combine2(vec_ptr v, data_t *dest) {
    long i;
    long length = vec_length(v);
    *dest = IDENT;
    for (int i = 0; i < length; ++i) {
        data_t val;
        get_vec_element(v, i, &val);
        *dest = *dest OP val;
    }
}
```

##### 减少过程调用

* 从 combine2 的代码可以看出每次循环迭代都会调用 get_vec_element 来获取下一个元素的调用，对每个向量引用，这个函数要把向量索引 i 与循环边界做比较，很明显会造成低效率
  * 解决方法：增加一个抽象函数 get_vec_start，返回数组的起始地址
  * **经过测试发现并没有明显的性能提升**，说明内循环的其它操作造形成了瓶颈

优化后的代码

```c++
data_t *get_vec_start(vec_ptr v) {
    return v->data;
}

void combine3(vec_ptr v, data_t *dest) {
    long i;
    long length = vec_length(v);
    data_t *data = get_vec_start(v);
    *dest = IDENT;
    for (i = 0; i < length; ++i) {
        *dest = *dest OP data[i];
    }
}
```

##### 消除不必要的内存引用

* 引入临时变量 acc，消除不必要的内存读写，它在循环中用来累积计算出来的值，只有完成循环之后才会把结果放入 dest 中

```c++
void combine4(vec_ptr v, data_t *dest) {
    long i;
    long length = vec_length(v);
    data_t *data = get_vec_start(v);
    data_t acc = IDENT;
    for (i = 0; i < length; ++i) {
        acc = acc OP data[i];
    }
    *dest = acc;
}
```

#### 理解现代处理器

* 两种下界描述了程序最大性能
  * 当一系列操作必须按照严格顺序执行时，就会遇到延迟界限，因为在下一条指令开始之前，这条指令必须结束，当代码中的数据相关限制了处理器利用指令集并行的能力时，延迟界限能够限制程序性能
  * 吞吐量界限刻画了处理器功能单元的原始计算力，这个界限是程序性能的终极限制

##### 整体操作

* 现代处理器可以再每个时钟周期执行多个操作，而且是乱序的，意思就是指令执行的顺序不一定要与它们在机器程序中的顺序一致，整个设计由两部分组成（指令控制单元和执行单元），前者负责从内存中读出指令序列，并根据这些指令序列生成一组针对程序数据的基本操作，后者执行这些操作。
  * ICU 从指令高速缓存中读取指令（指令高速缓存是一个特殊的高速存储器，它包含最近访问的指令）
  * ICU 会在当前指令执行很早之前取指，并发送到 EU，当遇到分支时，采用分支预测技术猜测处理器是否会选择分支和预测分支目标地址，使用投机执行技术取出位于预测分支跳到的指令，并对指令译码，如果确定分支预测错误，将会重新设置分支点状态，并开始取出和执行另一个方向上的指令
  * 指令译码逻辑接收实际的程序指令，并将它们转换成基本操作
  * 在 X86-64 实现中一条指令可能转换一条或多条操作，译码逻辑对指令进行分解，允许并行的执行多条指令的不同部分
  * EU 接收取指单元的操作
  * 读写内存是由加载和储存单元实现的，加载单元处理从内存读数据到处理器的操作，储存单元处理从处理器写数据到内存的操作，两者通过数据告诉缓存来访问内存
  * 投机技术对操作求值的结果直到确定应该实际执行这些指令之前都不会放在程序寄存器或数据内存中
  * 分支操作被放倒 EU 用来确定分支预测是否正确，如果预测错误会导致很大的性能开销

##### 功能单元性能

* 下表展示了一些算术运算的性能，每个运算都可以分为三个阶段
  * 延迟阶段：它表示完成运算所需要的总时间
  * 发射时间：它表示两个连续的同类型运算之间需要的最小时钟周期数
  * 容量：它表示能够执行该运算的功能单元的数量

* 从图中可以看出整数到浮点运算延迟是增加的，加法运算和乘法运算的发射时间都为 1，意思是说每个时钟周期处理器都可以开始一条新的这样的运算，这种很短的发射时间都是通过流水线实现的
* 浮点加法器包含三个阶段（所以为三个周期延迟），一个阶段处理指数值，一个阶段将小数相加，而另一个阶段对结果进行舍入
* 只有当执行运算时连续的，逻辑上是独立的时候，才能利用这种功能
* 除法的延迟与发射时间是一样的，这说明在开始一条新的运算之前，除法器必须完成整个除法，除法的延迟和发射时间是以范围形式给出的，因为某些被除数和除数组合比其他的组合需要更多的步骤，因此**除法相对其他运算来说是一个相对开销很大的运算**

| 运算 | 整数 | 整数 | 整数 | 浮点数 | 浮点数 | 浮点数 |
| :--: | :--: | :--: | :--: | :----: | :----: | :----: |
|      | 延迟 | 发射 | 容量 |  延迟  |  发射  |  容量  |
| 加法 |  1   |  1   |  4   |   3    |   1    |   1    |
| 乘法 |  3   |  1   |  1   |   5    |   1    |   2    |
| 除法 | 3~30 | 3~30 |  1   |  3~15  |  3~15  |   1    |



##### 处理器操作的抽象模型

* 下图给出了影响程序执行时间的操作相关和数据相关，程序是由加法和乘法并行的，由上表可知乘法比加法更加耗时，因此主要制约程序性能的是乘法操作

<img src="/Users/user/Downloads/归档/img/1591793619497.jpg" alt="img-1591793619497" style="zoom:50%;" />

* 通过上面一系列的分析可以得出结论，在并行操作中，延迟界限（上例的加法和乘法同时执行，因此乘法和加法的运行时差就是延迟界限）是基本的限制，决定了我们的合并运算能有多快

#### 循环展开

* 循环展开是一种程序变换，通过增加每次迭代计算的元素数量，减少循环的迭代次数

用循环展开对程序进行优化（**由原来的一项一项的相加改为两项两项的相加，最后加上剩余的项数**）

```c++
void combine5(vec_ptr v,data_t *dest){
  long i;
  long length = vec_length(v);
  long limit = length - 1;
  data_t *data = get_vec_start(v);
  data_t acc = IDENT;
  
  for(i=0; i<limit; i+=2){
    acc = (acc OP data[i]) OP data[i+1];
  }
   for(; i<length; i++){
    acc = acc OP data[i];
  }
  *dest = acc;
}
```

