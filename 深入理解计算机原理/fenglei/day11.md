### 第五章 优化程序性能

* 编写高效的程序需要以下几点
  * 选择一组适当的算法和数据结构
  * 写出编译器能够有效优化以转换成高效可执行代码的源代码
* 为了使程序性能最大化，程序要和编译器都需要一个目标机器的模型，指明如何处理指令，以及各个操作的时序性
* 利用程序的指令级并行能力，同时执行多条指令

#### 优化编译器的能力和局限性

* 现代编译器运用复杂精细的算法来确定一个程序中计算的是什么值，以及它们是被如何使用的，然后会利用一些机会来简化表达式，在几个不同的地方使用同一个计算，以及降低一个给定的计算必须被执行的次数
  * 比如 GCC 编译器以命令选项 “-Og” 调用 GCC 是让 GCC使用一组基本的优化，-O1或更高（-O2 或 -O3）调用 GCC 会让它使用更大量的优化
  * 两个指针可能指向同一个内存位置的情况称为 内存别名使用，在只执行安全的优化中，编译器必须假设不同的指针可能会指向内存中同一个位置
  * **内存别名的使用可能会导致意想不到的程序行为，从而限制优化策略**

```c++
// 6 次内存引用（2次读 *xp，2次读 *yp，2次写 *xp）
void twiddle1(long *xp,long *yp){
    *xp += *yp;
    *xp += *yp;
}

// 3 次内存引用（读 *xp，读 *yp，写 *xp）
void twiddle2(long *xp,long *yp){
    *xp += 2 * *yp;
}

// 上面的代码要考虑到 xp = yp 的情况，如果 xp = yp twiddle1 为 xp 的 4 倍，而 twiddle2 为 xp 的 3 倍
```

#### 表示程序的性能

* 我们引入度量标准**每元素的周期数（CPE）**，作为一种表示程序性能并指导我们改进代码的方法。CPE 这种度量标准帮助我们在更细节上理解迭代程序的循环性能，CPE 越小，证明程序的性能越好

#### 程序示例

* 下面的例子说明一个抽象的程序是如何被系统的转换成有效代码

```c++
typedef long data_t;

typedef struct {
    long len;
    data_t *data;
} vec_rec, *vec_ptr;

// 创建 vec 
vec_ptr new_vec(long len) {
    vec_ptr result = (vec_ptr) malloc(sizeof(vec_rec));
    data_t *data = NULL;
    if (!result) {
        return NULL;
    }
    result->len = len;
    if (len > 0) {
        data = (data_t *) calloc(len, sizeof(data_t));
        if (!data) {
            free(result);
            return NULL;
        }
    }
    result->data = data;
    return result;
}

// 获取指定位置的一条数据
int get_vec_element(vec_ptr v, long index, data_t *dest) {
    if (index < 0 || index >= v->len) {
        return 0;
    }
    *dest = v->data[index];
    return 1;
}

// 返回 vec 长度
long vec_length(vec_ptr v) {
    return v->len;
}

#define IDENT 0
#define OP +

// 获取 data_t 的总和
void combine1(vec_ptr v, data_t *dest) {
    long i;
    *dest = IDENT;
    for (int i = 0; i < vec_length(v); ++i) {
        data_t val;
        get_vec_element(v, i, &val);
        *dest = *dest OP val;
    }
}
```

##### 消除循环的低效率

* combine1 调用函数 vec_length(v) 作为 for 循环的测试条件，循环翻译成机器级程序，每次循环迭代时都必须对测试条件求值，并且向量的长度不会随着循环的进行而改变，因此只要计算一次向量的长度就可以了

优化后的代码

```c++
void combine2(vec_ptr v, data_t *dest) {
    long i;
    long length = vec_length(v);
    *dest = IDENT;
    for (int i = 0; i < length; ++i) {
        data_t val;
        get_vec_element(v, i, &val);
        *dest = *dest OP val;
    }
}
```

##### 减少过程调用

* 从 combine2 的代码可以看出每次循环迭代都会调用 get_vec_element 来获取下一个元素的调用，对每个向量引用，这个函数要把向量索引 i 与循环边界做比较，很明显会造成低效率
  * 解决方法：增加一个抽象函数 get_vec_start，返回数组的起始地址
  * **经过测试发现并没有明显的性能提升**，说明内循环的其它操作造形成了瓶颈

优化后的代码

```c++
data_t *get_vec_start(vec_ptr v) {
    return v->data;
}

void combine3(vec_ptr v, data_t *dest) {
    long i;
    long length = vec_length(v);
    data_t *data = get_vec_start(v);
    *dest = IDENT;
    for (i = 0; i < length; ++i) {
        *dest = *dest OP data[i];
    }
}
```

##### 消除不必要的内存引用

* 引入临时变量 acc，消除不必要的内存读写，它在循环中用来累积计算出来的值，只有完成循环之后才会把结果放入 dest 中

```c++
void combine4(vec_ptr v, data_t *dest) {
    long i;
    long length = vec_length(v);
    data_t *data = get_vec_start(v);
    data_t acc = IDENT;
    for (i = 0; i < length; ++i) {
        acc = acc OP data[i];
    }
    *dest = acc;
}
```

#### 理解现代处理器

* 两种下界描述了程序最大性能
  * 当一系列操作必须按照严格顺序执行时，就会遇到延迟界限，因为在下一条指令开始之前，这条指令必须结束，当代码中的数据相关限制了处理器利用指令集并行的能力时，延迟界限能够限制程序性能
  * 吞吐量界限刻画了处理器功能单元的原始计算力，这个界限是程序性能的终极限制

##### 整体操作

* 现代处理器可以再每个时钟周期执行多个操作，而且是乱序的，意思就是指令执行的顺序不一定要与它们在机器程序中的顺序一致，整个设计由两部分组成（指令控制单元和执行单元），前者负责从内存中读出指令序列，并根据这些指令序列生成一组针对程序数据的基本操作，后者执行这些操作。
  * ICU 从指令高速缓存中读取指令（指令高速缓存是一个特殊的高速存储器，它包含最近访问的指令）
  * ICU 会在当前指令执行很早之前取指，并发送到 EU，当遇到分支时，采用分支预测技术猜测处理器是否会选择分支和预测分支目标地址，使用投机执行技术取出位于预测分支跳到的指令，并对指令译码，如果确定分支预测错误，将会重新设置分支点状态，并开始取出和执行另一个方向上的指令
  * 指令译码逻辑接收实际的程序指令，并将它们转换成基本操作
  * 在 X86-64 实现中一条指令可能转换一条或多条操作，译码逻辑对指令进行分解，允许并行的执行多条指令的不同部分
  * EU 接收取指单元的操作
  * 读写内存是由加载和储存单元实现的，加载单元处理从内存读数据到处理器的操作，储存单元处理从处理器写数据到内存的操作，两者通过数据告诉缓存来访问内存
  * 投机技术对操作求值的结果直到确定应该实际执行这些指令之前都不会放在程序寄存器或数据内存中
  * 分支操作被放倒 EU 用来确定分支预测是否正确，如果预测错误会导致很大的性能开销

##### 功能单元性能

* 下表展示了一些算术运算的性能，每个运算都可以分为三个阶段
  * 延迟阶段：它表示完成运算所需要的总时间
  * 发射时间：它表示两个连续的同类型运算之间需要的最小时钟周期数
  * 容量：它表示能够执行该运算的功能单元的数量

* 从图中可以看出整数到浮点运算延迟是增加的，加法运算和乘法运算的发射时间都为 1，意思是说每个时钟周期处理器都可以开始一条新的这样的运算，这种很短的发射时间都是通过流水线实现的
* 浮点加法器包含三个阶段（所以为三个周期延迟），一个阶段处理指数值，一个阶段将小数相加，而另一个阶段对结果进行舍入
* 只有当执行运算时连续的，逻辑上是独立的时候，才能利用这种功能
* 除法的延迟与发射时间是一样的，这说明在开始一条新的运算之前，除法器必须完成整个除法，除法的延迟和发射时间是以范围形式给出的，因为某些被除数和除数组合比其他的组合需要更多的步骤，因此**除法相对其他运算来说是一个相对开销很大的运算**

| 运算 | 整数 | 整数 | 整数 | 浮点数 | 浮点数 | 浮点数 |
| :--: | :--: | :--: | :--: | :----: | :----: | :----: |
|      | 延迟 | 发射 | 容量 |  延迟  |  发射  |  容量  |
| 加法 |  1   |  1   |  4   |   3    |   1    |   1    |
| 乘法 |  3   |  1   |  1   |   5    |   1    |   2    |
| 除法 | 3~30 | 3~30 |  1   |  3~15  |  3~15  |   1    |



##### 处理器操作的抽象模型

* 下图给出了影响程序执行时间的操作相关和数据相关，程序是由加法和乘法并行的，由上表可知乘法比加法更加耗时，因此主要制约程序性能的是乘法操作

<img src="/Users/user/Downloads/归档/img/1591793619497.jpg" alt="img-1591793619497" style="zoom:50%;" />

* 通过上面一系列的分析可以得出结论，在并行操作中，延迟界限（上例的加法和乘法同时执行，因此乘法和加法的运行时差就是延迟界限）是基本的限制，决定了我们的合并运算能有多快

#### 循环展开

* 循环展开是一种程序变换，通过增加每次迭代计算的元素数量，减少循环的迭代次数

用循环展开对程序进行优化（**由原来的一项一项的相加改为两项两项的相加，最后加上剩余的项数**）

```c++
void combine5(vec_ptr v, data_t *dest) {
    long i;
    long length = vec_length(v);
    long limit = length - 1;
    data_t *data = get_vec_start(v);
    data_t acc = IDENT;

    for (i = 0; i < limit; i += 2) {
        acc = (acc OP data[i]) OP data[i + 1];
    }
    for (; i < length; i++) {
        acc = acc OP data[i];
    }
    *dest = acc;
}
```

#### 调高并行性 

* 硬件具有以跟高速率执行乘法和加法的潜力，但是代码不能利用这种能力，即使循环展开也不能，因为我们将累积值放在一个单独的变量 acc 中，在前面的计算完成都不能计算 acc 的新值。虽然计算 acc 新值的功能单元能够每个时钟周期开始一个新的操作，但是它只会每 L 个周期开始一条新操作，这里 L 是合并操作的延迟。现在我们试图打破这种顺序相关，得到比延迟更好性能的方法

##### 多个累积变量

* 下面的代码演示了 2*2循环展开，它即使用了两次循环展开，以每次迭代合并更多的元素，也使用了两路并行，将索引数为偶数的元素累积在变量 acc0 中，而索引值为奇数的元素累积在变量 acc1 中，之后对于向量长度不为 2 的倍数时，第二次循环累积所有剩下的元素，最后对 acc0 和 acc1 应用合并运算，得出最终结果
* 2*2 循环对所有情况都得到了改进，可以使性能显著增加

改进代码

```c++
void combine6(vec_ptr v, data_t *dest) {
    long i;
    long length = vec_length(v);
    long limit = length - 1;
    data_t *data = get_vec_start(v);
    data_t acc0 = IDENT;
    data_t acc1 = IDENT;

    for (i = 0; i < limit; i += 2) {
        acc0 = acc0 OP data[i];
        acc1 = acc1 OP data[i + 1];
    }
    for (; i < length; i++) {
        acc0 = acc0 OP data[i];
    }
    *dest = acc0 OP acc1;
}
```

##### 重新结合变换

* 第二种打破顺序相关从而使性能调高到延迟界限的方法，下面函数与 combine5 的展开代码唯一区别在于内循环中元素合并的方式，差别仅在于两个括号如何放置，我们称之为重新结合变换，通过括号改变了向量元素与累积值 acc 的合并顺序
* 重新结合变换能够减少计算中关键路径上操作的数量，通过更好的利用功能单元的流水线能力得到更好的性能，但是对浮点运算不保证是可结合的，因此循环展开和并行的累积在多个值中，是提高性能更可靠的方法

```c++
void combine7(vec_ptr v, data_t *dest) {
    long i;
    long length = vec_length(v);
    long limit = length - 1;
    data_t *data = get_vec_start(v);
    data_t acc = IDENT;

    for (i = 0; i < limit; i += 2) {
      	// 与 combine5 唯一的区别是括号的位置不同
        acc = acc OP (data[i] OP data[i + 1]);
    }
    for (; i < length; i++) {
        acc = acc OP data[i];
    }
    *dest = acc;
}
```

##### 优化合并代码的结果小结

* 调高并行性通常来讲有两种方式
  * 在二次展开中拆分操作使用多个累积变量的方法来使各个操作并行减少延迟等待的事件
  * 减少计算中关键路径上的操作数量称为重新结合变量，减少关键赋值的次数提高程序性能
* 通过调高并行性并展开二次等一系列优化，上述案例的性能在在其他条件不变的情况下性能提高了 10 倍，说明现代处理器具有相当的计算能力，但是需要我们按照非常程式化的方式编写程序以便于将这些能力诱发出来

#### 一些限制因素

* 寄存器溢出
  * 如果我们将并行度 P 超过了可用的寄存器数量，那么编译器就会产生溢出，将某些值存放到内存中，通常是在运行时堆栈分配空间，比如把  combine6 的多累积变量模式扩展到 k = 10 或 k = 20（现代 x86-64 寄存器有 16 个寄存器，并可以使用 16 个 YMM 寄存器来保存浮点数）时，超过了寄存器数量，程序必须在栈上分配一些变量，这就导致了程序性能可能比之前更差
  * 一般情况下 x86-64 有足够的寄存器，大多数循环在出现寄存器溢出之前就将达到吞吐量限制

* 分支预测和预测错误处罚
  * C 语言如何保证分支预测触发不阻碍程序效率是个很复杂的问题，但是可以注意以下几点
    * 不要过分关心可预测的分支
    * 书写适合用条件传送实现的代码，GCC 能为一种更 功能性 风格书写的代码产生传送条件，这种风格对立一种更 命令式 的风格（下面举例）
    * 命令式风格代码主要看预测对错，如果预测正确性能比功能性代码号，预测错误则性能极差（3 ~ 13）功能性风格代码避免了处理器的预测，因此性能平稳（4 左右）

```c++
// 命令式风格代码
void minmax1(long a[], long b[], long n) {
    long i;
    for (int i = 0; i < n; ++i) {
        if (a[i] > b[i]) {
            long t = a[i];
            a[i] = b[i];
            b[i] = t;
        }
    }
}

// 功能性风格代码
void minmax2(long a[], long b[], long n) {
    long i;
    for (int i = 0; i < n; ++i) {
        long min = a[i] < b[i] ? a[i] : b[i];
        long max = a[i] < b[i] ? b[i] : a[i];
        a[i] = min;
        b[i] = max;
    }
}

```



#### 理解内存性能

* 现代处理器有专门的功能单元来执行加载的储存操作，这些单元内部的缓冲区来保存未完成的内存操作请求集合。例如：参考机有两个加载单元，每一个可以保存多达 72 个未完成的读请求。它还有一个储存单元，其存储缓冲区能保存最多 42 个写请求。每个这样的单元通常可以每个时钟周期开始一个操作

##### 加载性能

* 要确定一台机器上的加载延迟，我们可以建立由一系列加载操作组成的一个计算，一条加载操作的结果决定下一条操作的地址。

```c++
typedef struct ELE {
    struct ELE *next;
    long data;
} list_ele, *list_ptr;

long list_len(list_ptr ls) {
    long len = 0;
    while (ls) {
        len++;
        ls = ls->next;
    }
    return len;
}
```

#### 性能提高技术

* 优化程序程序性能的基本策略
  * 高级设计：为遇到的问题选择适当的算法和数据结构。
  * 基本编码原则：避免限制优化的因素，这样编译器就能产生高效代码
    * 消除连续的函数调用，在可能时，将计算移到循环外。考虑有选择的妥协程序的模块性已获得更大的效率
    * 消除不必要的内存引用。应用临时变量来保存中间结构，只有在最后的值计算出来时，才将结构存放到数组或全局变量中
  * 低级优化，结构化代码以利用硬件功能
    * 展开循环，降低开销，并且使得进一步的优化称为可能
    * 通过使用例如多个累积变量和重新结合等技术，找到方法提高指令集并行
    * 用功能性的风格重写条件操作，使得编译采用条件数据传送