并发：

逻辑控制流在时间上重叠，那么它们就是并发的(concurrent)，这种常见的现象称为并发（concurrency)

应用级并发作用:

1. 访问慢速 I/O 设备
2. 与人交互
3. 通过推迟工作以降低延迟
4. 服务多 个网络客户端
5. 在多核机器上进行并行计算
6. 进程
7. 1/0 多 路复用
8. 线程



12.1 基于进程的并发编程

构造并发程序最简单的方法就是用进程，使用那些大家都很熟悉的函数，像 fork,exec和 waitpid

![](https://gitee.com/andylinchuanxin/bookimagehome/raw/master/img/12-1.png)

![](https://gitee.com/andylinchuanxin/bookimagehome/raw/master/img/12-2.png)

![](https://gitee.com/andylinchuanxin/bookimagehome/raw/master/img/12-3.png)

![](https://gitee.com/andylinchuanxin/bookimagehome/raw/master/img/12-4.png)

12.1. 1 基于进程的并发服务器

服务器，有几点**重要内容需要说明**：

- 首先，通常服务器会运行很长的时间，所以我们必须要包括一个 **SIGCHLD** 处理程序，来回收僵死（zombie)子进程的资源（第 4〜9 行）。 因为当 **SIGCHLD** 处理程序执行时，**SIGCHLD** 信号是阻塞的，而 **Linux** 信号是不排队的，所以 **SIGCHLD** 处理程序必须准备好回收多个僵死子进程的资源

- 其次，父子进程必须关闭它们各自的 **connfd**(分别为第 33 行和第 30 行）副本。就像我们已经提到过的，这对父进程而言尤为重要，它必须关闭它的已连接描述符，以避免内存泄漏

- 最后，因为套接字的文件表表项中的引用计数，直到父子进程的 **connfd**都关闭了，到客户端的连接才会终止

  

12.1.2 进程的优劣

- 对于在父、子进程间共享状态信息，进程有一个非常清晰的模型：共享文件表，但是不共享用户地址空间

- 另一方面，独立的地址空间使得进程共享状态信息变得更加困难。为了共享信息，它们必须使用显式的 **IPC**(进程间通信）机制。

- **基于进程的设计的另一个缺点是，它们往往比较慢，因为进程控制和 IPC 的开销很高**

  

12.2 基于 I/O 多路复用的并发编程

个解决办法就是 **I/O** 多 路复用（I/O multiplexing)技术:

基本的思路就是使用 **select** 函数，要求内核挂起进程，只有在一个或多个 **I/O** 事件发生后，才将控制返回给应用程序



12.2.1 基于 I/O 多路复用的并发事件驱动服务器

I/O 多路复用可以用做并发事件驱动（event-driven)程序的基础，在事件驱动程序中，某些事件会导致流向前推进,思路是：

一般的思路是将逻辑流模型化为**状态机**

一个状态机（**state** **machine)**就是一组状态（**state**)、输入事件（**input** **event****)**和转移（**transition**)，其中转移是将状态和输人事件映射到状态



12.2.2 I/O 多路复用技术的优劣

优点：

- 事件驱动设计的一个优点是，它比基于进程的设计给了程序员更多的对程序行为的控制
- 一个基于 **I/O** 多路复用的事件驱动服务器是运行在单一进程上下文中的，因此每个逻辑流都能访问该进程的全部地址空间。这使得在流之间共享数据变得很容易

缺点：

- 编码复杂

  

12.3 基于线程的并发编程

两种创建并发逻辑流的方法：

- 为每个流使用了单独的进程，内核会自动调度每个进程，而每个进程有它自己的私有地址空间，这使得流共享数据很困难
- 我们创建自己的逻辑流，并利用 I/O 多 路复用来显式地调度流。因为只有一个进程，所有的流共享整个地址空间

1. **线程（thread)就是运行在进程上下文中的逻辑流**
2. 每个线程都有它自己的线程上下文（thread context), 包括一个唯一的整数线程，栈、栈指针、程序计数器、通用目的寄存器和条件码。
3. 所有的运行在一个进程里的线程共享该进程的整个虚拟地址空间



12.3.1 线程执行模型

![](https://gitee.com/andylinchuanxin/bookimagehome/raw/master/img/12-12.png)

1. 每个进程开始生命周期时都是单一线程，这个线程称为主线程（main thread)
2. 在某 一时刻，主线 程创建一个对 等线程(peer thread), 从这个时间点开始，两个线程就并发地运行。
3. 最后，因为主线程执行一个 慢速系 统调用，比如：**例如 read 或者sleep或者因为被系统的间隔计时器中断，控制就会通过上下文切换传递到对等线程。对等线程会执行一段时间，然后控制传递回主线程，依次类推**

注意：

- 在一些重要的方面，线程执行是不同于进程的，因为一个线程的上下文要比一个进程的上下文小得多，线程的上下文切换要比进程的上下文切换快得多
- 线程不像进程那样，不是按照严格的父子层次来组织的。和一个进程相关的线程组成一个对等(线程）池，独立于其他线程创建的线程。主线程和其他线程的区别仅在于它总是进程中第一个运行的线程。对等（线程）池概念的主要影响是，一个线程可以杀死它的任何对等线程，或者等待它的任意对等线程终止
- **每个对等线程都能读写相同的共享数据**



12.3.2 **Posix** 线程

Posix 线程(Pthreads)是在 C 程序中处理线程的一个标准接口



12.3.3 创建线程

线程通过调用 **pthread_create** 函数来创建其他线程



12.3.4 终止线程

- 当顶层的线程例程返回时，线程会隐式地终止
- 通过调用 **pthread_exit** 函数，线程会显式地终止，如果主线程调用 pthread_exit,它会等待所有其他对等线程终止，然后再终止主线程和整个进程，返回值为 ：**thread_return**
- 某个对等线程调用 **Linux** 的 **exit** 函数，该函数终止进程以及所有与该进程相关的线程
- 另一个对等线程通过以当前线程 **ID** 作为参数调用 **pthread_cancel** 函数来终止当前线程



12.3.5 回收已终止线程的资源

线程通过调用 **pthreadjoin** 函数等待其他线程终止

**pthreadjoin** 函数会阻塞，直到线程 **tid** 终止，将线程例程返回的通用（void*)指 针赋值为 **thread_return** 指向的位置，然后回收已终止线程占用的所有内存资源

**注意，和 Linux 的 wait 函数不词，pthreadjoin 函数只能等待一个指定的线程终止。没有办法让 pthread_Wait 等待任意一个线程**



12.3.6 分离线程

- 在任何一个时间点上，线程是可结合的（joinable)或者是分离的（detached)。
- 一个可结合的线程能够被其他线程收回和杀死。在被其他线程回收之前，它的内存资源（例如栈）是 不释放的。
- 相反，一个分离的线程是不能被其他线程回收或杀死的。它的内存资源在它终止时由系统自动释放
- 为了避免内存泄漏，每个可结合线程都应该要么**被其他线程显式地收回，要么通过调用 pthreacLdetach 函数被分离**
- **pthread_detach** 函数分离可结合线程 tid,线程能够通过以 **pthread_self**()为参数的 **pthread_detac.h** 调用来分离它们自己



12.3.7 初始化线程

**pthread_once** 函数允许你初始化与线程例程相关的状态



12.3.8 基于线程的并发服务器

**问题是在线程例程中避免内存泄漏**

**既然不显式地收回线程，就必须分离每个线程，使得在它终止时它的内存资源能够被收回**



12.4 多线程程序中的共享变量

线程很有吸引力的一个方面是多个线程很容易共享相同的程序变量



12.4.1 线程内存模型

- 一组并发线程运行在一个进程的上下文中。每个线程都有它自己独立的线程上下文，包括线程 ID,栈、栈指针、程序计数器、条件码和通用目的寄存器值。每个线程和其他线程一起共享进程上下文的剩余部分

- 这包括整个用户虚拟地址空间，它是由只读文本(代码）、 读/写数据、堆以及所有的共享库代码和数据区域组成的

- 线程也共享相同的打开文件的集合

  

12.4.2 将变量映射到内存

多线程的 **C** 程序中变量根据它们的存储类型被映射到虚拟内存:

- 全局变量。全局变量是定义在函数之外的变量,在运行时，虚拟内存的读/写区域只包含每个全局变量的一个实例，任何线程都可以引用
- 本地自动变量。本地自动变量就是定义在函数内部但是没有 **static** 属性的变量,在运行时，每个线程的栈都包含它自己的所有本地自动变量的实例。即使多个线程执行同一个线程例程时也是如此
- 本地静态变量。本地静态变量是定义在函数内部并有 **static** 属性的变量。和全局变量一样，虚拟内存的读/写区域只包含在程序中声明的每个本地静态变量的一个实例



12.4.3 共享变量

- 我们说一个变量 v是共享的，当且仅当它的一个实例被一个以上的线程引用
- myid 不是共享的，因为它的两个实例中每一个都只被一个线程引用
- **认识到像 msgs 这样的本地自动变量也能被共享是很重要的**



12.5 用信号量同步线程

共享变量是十分方便，但是它们也引入了同 步错误（synchronization error)的可能性



12.5.1  进度图

进度图（progress graph)将 **n** 个并发线程的执行模型化为一条 **n** 维笛卡儿空间中的轨迹线

![](https://gitee.com/andylinchuanxin/bookimagehome/raw/master/img/12-20.png)



12.5.2 信号量

基于一种信号量（semaphore)的特殊类型变量



12.5.3 使用信号量来实现互斥

信号量提供了一种很方便的方法来确保对共享变量的互斥访问



12.5.4 利用信号量来调度共享资源

- 除了提供互斥之外，信号量的另一个重要作用是调度对共享资源的访问
- 一个线程用信号量操作来通知另一个线程，程序状态中的某个条件已经为真了。两个经典而有用的例子是生产者-消费者和读者-写者问题

1. 生产者-消费者问题

   ![](https://gitee.com/andylinchuanxin/bookimagehome/raw/master/img/12-23.png)



12.6 使用线程提高并行性



12.7其他并发问题

- 线程安全
- 可重入性
- 在线程化的程序中使用已存在的库函数
- 竞争，当一个程序的正确性依赖于一个线程要在另一个线程到达 点之前到达它的控制流中的 I点时，就会发生竞争(race)，通常发生竞争是因为程序员假定线程将按照某种特殊的轨迹线穿过执行状态空间，而忘记了另一条准则**规定**：**多线程的程序必须对任何可行的轨迹线都正确工作**
- 死锁，信号量引入了一种潜在的令人厌恶的运行时错误，叫做死锁（deadlock), 它指的是一组线程被阻塞了，等待一个永远也不会为真的条件。进度图对于理解死锁是一个无价的工具。

![](https://gitee.com/andylinchuanxin/bookimagehome/raw/master/img/12-44.png)

**死锁的重要知识**：

1. 程序员使用 **P** 和 **V** 操作顺序不当，以至于两个信号量的禁止区域重叠。如果某个执行轨迹线碰巧到达了死锁状态 d那么就不可能有进一步的进展了，因为重叠的禁止区域阻塞了每个合法方向上的进展。换句话说，程序死锁是因为每个线程都在等待其他线程执行一个根不可能发生的 **V** 操作
2. 重叠的禁止区域引起了一组称为死锁区域（deadlock region)的状态。如果一个轨迹线碰巧到达了一个死锁区域中的状态，那么死锁就是不可避免的了。轨迹线可以进入死锁区域，但是它们不可能离开
3. 死锁是一个相当困难的问题，因为它不总是可预测的。一些幸运的执行轨迹线将绕开死锁区域，而其他的将会陷入这个区域。图 12-44 展示了每种情况的一个示例。对于程序员来说，这其中隐含的着实令人惊慌。你可以运行一个程序 1000 次不出任何问题，但是一次它就死锁了。或者程序在一台机器上可能运行得很好，但是在另外的机器上就会死锁。最糟糕的是，错误常常是不可重复的，因为不同的执行有不同的轨迹线

**程序死锁有很多原因，要避免死锁一般而言是很困难的。然而，当使用二元信号量来实现互斥时**

![](https://gitee.com/andylinchuanxin/bookimagehome/raw/master/img/12-45.png)